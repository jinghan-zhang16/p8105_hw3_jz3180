Homework 3
================
Jinghan Zhang
October 6, 2020

## Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(p8105.datasets)
data("instacart")
```

This dataset contains 1384617 rows and 15 columns. Observations are at
the level of items in orders by user. There are user / order variables –
user ID, order ID, order day, and order hour. There are also item
variables – name, aisle, department, and some numeric codes.

How many aisles, and which aisles are the most items from?

``` r
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

Let’s make a plot

``` r
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

![](p8105_hw3_jz3180_files/figure-gfm/plot%20aisles%20and%20items-1.png)<!-- -->
Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables
fruits”. Include the number of times each item is ordered in your
table.

``` r
instacart %>%
  filter(aisle %in% c("baking ingredience", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(rank)
```

    ## # A tibble: 6 x 4
    ## # Groups:   aisle [2]
    ##   aisle                    product_name                                  n  rank
    ##   <chr>                    <chr>                                     <int> <int>
    ## 1 dog food care            Snack Sticks Chicken & Rice Recipe Dog T…    30     1
    ## 2 packaged vegetables fru… Organic Baby Spinach                       9784     1
    ## 3 dog food care            Organix Chicken & Brown Rice Recipe          28     2
    ## 4 packaged vegetables fru… Organic Raspberries                        5546     2
    ## 5 dog food care            Small Dog Biscuits                           26     3
    ## 6 packaged vegetables fru… Organic Blueberries                        4966     3

``` r
  #knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples
and Coffee Ice Cream are ordered on each day of the week; format this
table for human readers (i.e. produce a 2 x 7 table).

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

``` r
library(ggridges)

accel_table = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
accel_table$day = 
  factor(accel_table$day, 
         levels 
            = c("Monday",
                "Tuesday",
                "Wednesday",
                "Thursday",
                "Friday",
                "Saturday",
                "Sunday")
         )

cleaned_accel_table <- accel_table[order(accel_table$week, accel_table$day),] %>%
  mutate(day_type = recode(day,
    "Saturday" = "Weekend",
    "Sunday" = "Weekend",
    .default = "Weekday"
    )) %>%
  relocate(day_type, .after = day)


aggregated <- cleaned_accel_table %>%
  mutate(total_activity = select(cleaned_accel_table, starts_with("activity_")) %>% rowSums()) %>%
  select(week, day_id, day, day_type, total_activity)
  
plot_table <- cleaned_accel_table %>%
  select(day, day_id, starts_with("activity_")) %>%
  gather(minute, activity, activity_1:activity_1440, factor_key = FALSE) %>%
  mutate(minute = as.numeric((str_replace(minute, "activity_", ""))))
  

ggplot(plot_table, aes(x = minute, y = activity))  + 
  geom_point(aes(color = day))
```

![](p8105_hw3_jz3180_files/figure-gfm/setup%20for%20Accel%20data-1.png)<!-- -->

``` r
library(p8105.datasets)
library(ggplot2)
data("ny_noaa") 

noaa <- ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, c("year", "month", "day"), sep = "-") %>%
  mutate(prcp = as.numeric(prcp)) %>%
  mutate(snow = as.numeric(snow)) %>%
  mutate(snwd = as.numeric(snwd)) %>%
  mutate(tmin = as.numeric(tmin)/10) %>%
  mutate(tmax = as.numeric(tmax)/10) %>%
  arrange(year, month, day)

tmax_month <- noaa %>%
  select(-prcp, -snow, -snwd, -tmin) %>%
  spread(day, tmax) %>%
  mutate(avg_tmax = rowMeans(select(., "01":"31"), na.rm = TRUE))

tmax_avg <- tmax_month %>%
  select(id, year, month, avg_tmax)

jan_tmax <- tmax_avg %>%
  filter(month == "01") %>%
  filter(!is.na(avg_tmax)) %>%
  select(id, year, avg_tmax)

jan_tmax %>%
  ggplot(aes(x=year, y=avg_tmax, group=id)) +
  theme_bw() +
  theme(panel.grid=element_blank()) +
  geom_line(size=0.2, alpha=0.1)
```

![](p8105_hw3_jz3180_files/figure-gfm/setup%20for%20noaa%20data-1.png)<!-- -->

``` r
jul_tmax <- tmax_avg %>%
  filter(month == "07") %>%
  filter(!is.na(avg_tmax)) %>%
  select(id, year, avg_tmax)

jul_tmax %>%
  ggplot(aes(x=year, y=avg_tmax, group=id)) +
  theme_bw() +
  theme(panel.grid=element_blank()) +
  geom_line(size=0.2, alpha=0.1)
```

![](p8105_hw3_jz3180_files/figure-gfm/setup%20for%20noaa%20data-2.png)<!-- -->

``` r
tmax_tmin <- noaa %>%
  select(tmax, tmin) %>%
  filter(!is.na(tmax)) %>%
  filter(!is.na(tmin))

tmax_tmin %>%
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex()
```

![](p8105_hw3_jz3180_files/figure-gfm/setup%20for%20noaa%20data-3.png)<!-- -->

``` r
snow_history <- noaa %>%
  select(year, snow) %>%
  filter(snow > 0) %>%
  filter(snow < 100)

snow_history %>%
  ggplot(aes(x = year)) +
  stat_count(width = 1)
```

![](p8105_hw3_jz3180_files/figure-gfm/setup%20for%20noaa%20data-4.png)<!-- -->
